{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, sys\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from Pegasus.api import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use  the requirements .txt file to get the needed packages\n",
    "! sudo pip3 install opencv-python <br>\n",
    "! sudo pip3 install --upgrade setuptools <br>\n",
    "! sudo pip3 install opencv-python <br>\n",
    "! sudo pip3 install optuna==2.0.0 <br>\n",
    "! sudo pip3 install matplotlib <br>\n",
    "! sudo pip3 install torch <br>\n",
    "! sudo pip3 install scikit-image <br>\n",
    "! sudo pip3 install torchvision <br>\n",
    "! sudo pip3 install pytorchtools <br>\n",
    "! sudo pip3 install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TO BE SURE: check the imports of the following\n",
    "\n",
    "import glob, os\n",
    "import argparse\n",
    "import tarfile\n",
    "import time\n",
    "import signal\n",
    "import joblib\n",
    "\n",
    "\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from skimage import io, transform\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "\n",
    "#custom utils\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from utils.util_checkpoint import extract_checkpoints, checkpoints_tar\n",
    "from utils.model_selection import BasicNet, PretrainedVGG16, PretrainedDenseNet121\n",
    "from utils.data_loader import CatDogsDataset\n",
    "\n",
    "\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_workflow import download_data, unzip_flatten_data, return_corrupted_files, return_input_files\n",
    "from util_workflow import add_input_wf_files, add_output_job1, add_output_job2, return_filenames_job2\n",
    "from util_workflow import split_data_filenames, add_input_tune_model,create_tar_and_pkl, create_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Pegasus API ---\n",
    "from Pegasus.api import *\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "props = Properties()\n",
    "props[\"dagman.retry\"] = \"2\"\n",
    "props[\"pegasus.transfer.arguments\"] = \"-m 1\"\n",
    "props.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_link = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
    "zip_data = \"kagglecatsanddogs_3367a.zip\"\n",
    "directory_to_extract_to = \".\"\n",
    "\n",
    "DOWNLOAD_DATA = False\n",
    "DATASET_SIZE = 12\n",
    "DATA_DIR = \"dev_data/\"\n",
    "UTILS_DIR = \"utils/\"\n",
    "DATA_SPLIT_FILE = \"data_split_id_list.pickle\"\n",
    "\n",
    "arch_names = [\"basicnet\", \"densenet121\", \"vgg16\"]\n",
    "CATS = \"PetImages/Cat\"\n",
    "DOGS = \"PetImages/Dog\"\n",
    "LABELS = {CATS: 0, DOGS: 1}\n",
    "NUM_EPOCHS = 4\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)   \n",
    "    \n",
    "if DOWNLOAD_DATA == True:\n",
    "    download_data(dataset_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid corrupted files for now\n",
    "corrupted_files = return_corrupted_files(\"corrupted_files.txt\")\n",
    "\n",
    "# Get names of image files that will serve as inputs to the workflow\n",
    "input_file_names = return_input_files(corrupted_files, DATASET_SIZE, DATA_DIR, LABELS)\n",
    "\n",
    "rc = ReplicaCatalog()\n",
    "\n",
    "input_preprocessing1 = add_input_wf_files(input_file_names, DATA_DIR,rc)\n",
    "input_preprocessing2 = add_output_job1(input_file_names)\n",
    "\n",
    "output_filenames_preprocessing2 =  return_filenames_job2(input_file_names)\n",
    "output_preprocessing2 = add_output_job2(output_filenames_preprocessing2)\n",
    "\n",
    "\n",
    "train_filenames,val_filenames,test_filenames,files_split_dict = split_data_filenames(output_filenames_preprocessing2)\n",
    "\n",
    "data_split_filenames = train_filenames + val_filenames + test_filenames\n",
    "output_data_split = add_input_tune_model(data_split_filenames)\n",
    "\n",
    "tune_model_files = train_filenames + val_filenames\n",
    "input_tune_model = add_input_tune_model(tune_model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_split_id_list.pickle'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SPLIT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.replica_catalog.ReplicaCatalog at 0x7f310c01a208>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_SPLIT_FILE, 'wb') as filename:\n",
    "    pickle.dump(files_split_dict, filename)\n",
    "    \n",
    "data_split_file = File(DATA_SPLIT_FILE)\n",
    "rc.add_replica(\"local\", DATA_SPLIT_FILE, str(Path(\".\").resolve() / DATA_SPLIT_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.replica_catalog.ReplicaCatalog at 0x7f310c01a208>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADDITIONAL PYTHON SCRIPS NEEDED BY TUNE_MODEL\n",
    "data_loader_fn = \"data_loader.py\"\n",
    "data_loader_file = File(data_loader_fn )\n",
    "rc.add_replica(\"local\", data_loader_fn, os.path.join(os.getcwd(), UTILS_DIR + data_loader_fn ))\n",
    "\n",
    "model_selction_fn = \"model_selection.py\"\n",
    "model_selction_file = File(model_selction_fn )\n",
    "rc.add_replica(\"local\", model_selction_fn, os.path.join(os.getcwd(), UTILS_DIR + model_selction_fn ))\n",
    "\n",
    "util_checkpoint_fn = \"util_checkpoint.py\"\n",
    "util_checkpoint_file = File(util_checkpoint_fn )\n",
    "rc.add_replica(\"local\", util_checkpoint_fn, os.path.join(os.getcwd(), UTILS_DIR + util_checkpoint_fn ))\n",
    "\n",
    "early_stopping_fn = \"pytorchtools.py\"\n",
    "early_stopping_file = File(early_stopping_fn )\n",
    "rc.add_replica(\"local\", early_stopping_fn, os.path.join(os.getcwd(), UTILS_DIR + early_stopping_fn ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hpo_study_checkpoint_vgg16.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_pkl(\"vgg16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILES FOR TUNE_MODEL.py VGG 16\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "vgg16_pkl = create_pkl(\"vgg16\")\n",
    "final_vgg16_pkl =  \"final_hpo_study_checkpoint_vgg16.pkl\"\n",
    "\n",
    "vgg16_pkl_file = File(vgg16_pkl)\n",
    "rc.add_replica(\"local\", vgg16_pkl, os.path.join(os.getcwd(), vgg16_pkl))\n",
    "\n",
    "final_vgg16_pkl_file = File(final_vgg16_pkl)\n",
    "\n",
    "rc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add our transformations to the TransformationCatalog.\n",
    "tc = TransformationCatalog()\n",
    "\n",
    "# Data preprocessing part 1 \n",
    "preprocess1 = Transformation(\n",
    "                \"preprocess1\",\n",
    "                site=\"local\",\n",
    "                pfn = str(Path(\".\").parent.resolve() / \"bin/data_preprocessing1.py\"), \n",
    "                is_stageable= True\n",
    "            )\n",
    "\n",
    "# Data preprocessing part 2\n",
    "preprocess2 = Transformation(\n",
    "                    \"preprocess2\", \n",
    "                   site = \"local\", \n",
    "                    pfn = str(Path(\".\").parent.resolve() / \"bin/data_preprocessing2.py\"), \n",
    "                    is_stageable = True\n",
    "              )\n",
    "\n",
    "# Data Split\n",
    "data_split = Transformation(\n",
    "                    \"data_split\", \n",
    "                    site = \"local\", \n",
    "                    pfn = str(Path(\".\").parent.resolve() / \"bin/data_split.py\"), \n",
    "                    is_stageable = True\n",
    "                )\n",
    "\n",
    "\n",
    "# Tune models\n",
    "tune_model_vgg16 = Transformation(\n",
    "                    \"tune_model_vgg16\", \n",
    "                    site = \"local\", \n",
    "                   pfn = str(Path(\".\").parent.resolve() / \"bin/tune_model.py\"), \n",
    "                    is_stageable = True\n",
    "                )\n",
    "\n",
    "# Choose best model and hyperparameters\n",
    "choose_best_model = Transformation(\n",
    "                    \"choose_best_model\", \n",
    "                    site = \"local\", \n",
    "                    pfn = str(Path(\".\").parent.resolve() / \"bin/choose_best_model.py\"), \n",
    "                    is_stageable = True\n",
    "                )\n",
    "\n",
    "tc.add_transformations(preprocess1 , preprocess2,data_split,tune_model_vgg16,choose_best_model)\n",
    "tc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Workflow -----------------------------------------------------------------\n",
    "# Set infer_dependencies=True so that they are inferred based on job input and output file usage.\n",
    "wf = Workflow(\"catVsdog-test-wf\", infer_dependencies=True)\n",
    "\n",
    "# Create Jobs. These objects store just that. The transformation (executable) used by the job.\n",
    "#The arguments passed to the executable. The input files used and the output files produced. \n",
    "\n",
    "\n",
    "job_preprocess_1 = Job(preprocess1)\\\n",
    "                    .add_inputs(*input_preprocessing1)\\\n",
    "                    .add_outputs(*input_preprocessing2)\n",
    "\n",
    "\n",
    "job_preprocess_2 = Job(preprocess2)\\\n",
    "                    .add_inputs(*input_preprocessing2)\\\n",
    "                    .add_outputs(*output_preprocessing2 )\n",
    "\n",
    "\n",
    "job_data_split = Job(data_split)\\\n",
    "                    .add_inputs(data_split_file,*output_preprocessing2)\\\n",
    "                    .add_outputs(*output_data_split) \n",
    "\n",
    "\n",
    "\n",
    "job_tune_model_vgg16 = Job(tune_model_vgg16)\\\n",
    "                    .add_args(\"-a\",\"vgg16\",\"-arch\", \"vgg16\", NUM_EPOCHS, NUM_TRIALS)\\\n",
    "                    .add_checkpoint(vgg16_pkl_file, stage_out=True)\\\n",
    "                    .add_inputs(*input_tune_model,data_loader_file,model_selction_file, early_stopping_file,util_checkpoint_file )\\\n",
    "                    .add_outputs(final_vgg16_pkl_file)\\\n",
    "                    .set_stdout(\"output_vgg16.txt\")\\\n",
    "                    .add_profiles(Namespace.PEGASUS, key=\"checkpoint.time\", value=1)\\\n",
    "                    .add_profiles(Namespace.PEGASUS, key=\"maxwalltime\", value=2)\n",
    "\n",
    "job_choose_best_model = Job(choose_best_model)\\\n",
    "                    .add_args(\"-sf\",\"final_hpo_study_checkpoint_vgg16.pkl\")\\\n",
    "                    .add_inputs(final_vgg16_pkl_file)\\\n",
    "                    .add_outputs(File(\"best_model.txt\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Workflow at 0x7f310bfef6a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.add_jobs(\n",
    "    job_preprocess_1,\n",
    "    job_preprocess_2,\n",
    "    job_data_split,\n",
    "    job_tune_model_vgg16,\n",
    "    job_choose_best_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "################\n",
      "# pegasus-plan #\n",
      "################\n",
      "2021.02.08 06:25:14.574 UTC:\n",
      "2021.02.08 06:25:14.579 UTC:   -----------------------------------------------------------------------\n",
      "2021.02.08 06:25:14.585 UTC:   File for submitting this DAG to HTCondor           : catVsdog-test-wf-0.dag.condor.sub\n",
      "2021.02.08 06:25:14.590 UTC:   Log of DAGMan debugging messages                 : catVsdog-test-wf-0.dag.dagman.out\n",
      "2021.02.08 06:25:14.595 UTC:   Log of HTCondor library output                     : catVsdog-test-wf-0.dag.lib.out\n",
      "2021.02.08 06:25:14.600 UTC:   Log of HTCondor library error messages             : catVsdog-test-wf-0.dag.lib.err\n",
      "2021.02.08 06:25:14.605 UTC:   Log of the life of condor_dagman itself          : catVsdog-test-wf-0.dag.dagman.log\n",
      "2021.02.08 06:25:14.610 UTC:\n",
      "2021.02.08 06:25:14.616 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2021.02.08 06:25:14.626 UTC:   -----------------------------------------------------------------------\n",
      "2021.02.08 06:25:15.243 UTC:   Your database is compatible with Pegasus version: 5.1.0dev\n",
      "2021.02.08 06:25:15.966 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009/catVsdog-test-wf-0.replicas.db\n",
      "2021.02.08 06:25:15.971 UTC:   Your database is compatible with Pegasus version: 5.1.0dev\n",
      "2021.02.08 06:25:16.020 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009/catVsdog-test-wf-0.replicas.db\n",
      "[WARNING]  Submitting to condor catVsdog-test-wf-0.dag.condor.sub\n",
      "2021.02.08 06:25:16.457 UTC:   Time taken to execute is 2.319 seconds\n",
      "\n",
      "Your workflow has been started and is running in the base directory:\n",
      "\n",
      "/home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009\n",
      "\n",
      "*** To monitor the workflow you can run ***\n",
      "\n",
      "pegasus-status -l /home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009\n",
      "\n",
      "\n",
      "*** To remove your workflow run ***\n",
      "\n",
      "pegasus-remove /home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m########################\u001b[0m------------]  67.7% ..Failure (\u001b[1;32mCompleted: 21\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 0\u001b[0m, \u001b[1;31mFailed: 1\u001b[0m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      "# pegasus-analyzer #\n",
      "####################\n",
      "Your database is compatible with Pegasus version: 5.1.0dev\n",
      "\n",
      "************************************Summary*************************************\n",
      "\n",
      "Submit Directory   : /home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009\n",
      "Total jobs         :     31 (100.00%)\n",
      "# jobs succeeded   :     21 (67.74%)\n",
      "# jobs failed      :      1 (3.23%)\n",
      "# jobs held        :      0 (0.00%)\n",
      "# jobs unsubmitted :      9 (29.03%)\n",
      "\n",
      "******************************Failed jobs' details******************************\n",
      "\n",
      "===========================tune_model_vgg16_ID0000004===========================\n",
      "\n",
      "last state: POST_SCRIPT_FAILED\n",
      "site: condorpool\n",
      "submit file: 00/00/tune_model_vgg16_ID0000004.sub\n",
      "output file: 00/00/tune_model_vgg16_ID0000004.out.002\n",
      "error file: 00/00/tune_model_vgg16_ID0000004.err.002\n",
      "\n",
      "-------------------------------Task #1 - Summary--------------------------------\n",
      "\n",
      "site        : condorpool\n",
      "hostname    : cae6425c697f\n",
      "executable  : /var/lib/condor/execute/dir_6757/tune_model_vgg16\n",
      "arguments   : -\n",
      "exitcode    : 3\n",
      "working dir : /var/lib/condor/execute/dir_6757\n",
      "\n",
      "-----------Task #1 - tune_model_vgg16 - ID0000004 - Kickstart stderr------------\n",
      "\n",
      "/usr/local/lib64/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "return torch._C._cuda_getDeviceCount() > 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your database is compatible with Pegasus version: 5.1.0dev\n",
      "\n",
      "************************************Summary*************************************\n",
      "\n",
      " Submit Directory   : /home/scitech/shared-data/pegasus-catdog-wf-master/scitech/pegasus/catVsdog-test-wf/run0009\n",
      " Total jobs         :     31 (100.00%)\n",
      " # jobs succeeded   :     21 (67.74%)\n",
      " # jobs failed      :      1 (3.23%)\n",
      " # jobs held        :      0 (0.00%)\n",
      " # jobs unsubmitted :      9 (29.03%)\n",
      "\n",
      "******************************Failed jobs' details******************************\n",
      "\n",
      "===========================tune_model_vgg16_ID0000004===========================\n",
      "\n",
      " last state: POST_SCRIPT_FAILED\n",
      "       site: condorpool\n",
      "submit file: 00/00/tune_model_vgg16_ID0000004.sub\n",
      "output file: 00/00/tune_model_vgg16_ID0000004.out.002\n",
      " error file: 00/00/tune_model_vgg16_ID0000004.err.002\n",
      "\n",
      "-------------------------------Task #1 - Summary--------------------------------\n",
      "\n",
      "site        : condorpool\n",
      "hostname    : cae6425c697f\n",
      "executable  : /var/lib/condor/execute/dir_6757/tune_model_vgg16\n",
      "arguments   : -\n",
      "exitcode    : 3\n",
      "working dir : /var/lib/condor/execute/dir_6757\n",
      "\n",
      "-----------Task #1 - tune_model_vgg16 - ID0000004 - Kickstart stderr------------\n",
      "\n",
      " /usr/local/lib64/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    wf.plan(submit=True)\\\n",
    "    .wait()\\\n",
    "    .analyze()\\\n",
    "    .statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './wf-output/best_model.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a5615158bf7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## CONFIRM best_model.txt contains hyperparameters for training best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./wf-output/best_model.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshow_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './wf-output/best_model.txt'"
     ]
    }
   ],
   "source": [
    "## CONFIRM best_model.txt contains hyperparameters for training best model\n",
    "\n",
    "show_results = open(\"./wf-output/best_model.txt\", \"r\")\n",
    "show_results.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
